{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two models,  cascaded models, unified model\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "matplotlib.use('TKAgg',warn=False, force=True)\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_file_process import read_pickle_data\n",
    "from common_plot import plotOneScatterLine\n",
    "from common_plot import plotOneScatter\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '../../input_output/one_person_diy_video_dataset/' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_scatter(x_lst_1, x_lst_2, y_lst_1, y_lst_2, x_label, y_label_1, y_label_2, title_name, write_dir):\n",
    "    fig,axes=plt.subplots(nrows=2, ncols=1)\n",
    "    axes[0].plot(x_lst_1, y_lst_1, zorder=1) \n",
    "    sc1 = axes[0].scatter(x_lst_1, y_lst_1, marker=\"o\", color=\"r\", zorder=2)\n",
    "    \n",
    "    axes[1].plot(x_lst_2, y_lst_2, zorder=1) \n",
    "    sc2 = axes[1].scatter(x_lst_2,y_lst_2, marker=\"x\", color=\"k\", zorder=2)\n",
    "    \n",
    "    axes[0].set(xlabel=x_label, ylabel=y_label_1)\n",
    "    axes[1].set(xlabel=x_label, ylabel=y_label_2)\n",
    "    \n",
    "    #axes[0].legend([sc1], [\"Admitted\"])\n",
    "    #axes[1].legend([sc2], [\"Not-Admitted\"])\n",
    "    axes[0].set_title(title_name)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    #plt.xticks(size = 12)\n",
    "    #plt.yticks(size = 12)\n",
    "    #plt.yticks(y, yticks)\n",
    "    #plt.show()\n",
    "    plt.savefig(write_dir + 'acc_video1.png', bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_whole_data_instances(data_file):\n",
    "\n",
    "    data = read_pickle_data(data_file)\n",
    "    print(\"data shape: \", data.shape)\n",
    "\n",
    "    y = np.expand_dims(data, axis=1)    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (1290,)\n",
      "data shape:  (1515,)\n",
      "arr_acc_model 1 2 mean:  0.8705679701136528 0.8498516309136567\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_two_scatter() missing 1 required positional argument: 'write_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b161fcf8665f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arr_acc_model 1 2 mean: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_acc_model1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_acc_model2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mplot_two_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_acc_model1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_acc_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_acc_model1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_acc_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Segment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_two_scatter() missing 1 required positional argument: 'write_dir'"
     ]
    }
   ],
   "source": [
    "\n",
    "video_dir_lst =  ['output_001_dance/', 'output_002_dance/', \\\n",
    "                    'output_003_dance/', 'output_004_dance/',  \\\n",
    "                    'output_005_dance/', 'output_006_yoga/', \\\n",
    "                    'output_007_yoga/', 'output_008_cardio/', \\\n",
    "                    'output_009_cardio/', 'output_010_cardio/']\n",
    "for predicted_video_dir in video_dir_lst:\n",
    "    \n",
    "    model2_dir  = parent_dir + predicted_video_dir + \"jumping_number_result/jumpingNumber_resolution_selection/intervalFrm-1_speedType-ema_minAcc-0.92/video_applied_detection_result/\"\n",
    "    \n",
    "    model2_acc_file = model2_dir + \"arr_acc_segment_.pkl\"\n",
    "    arr_acc_model2 = read_whole_data_instances(model2_acc_file)\n",
    "    \n",
    "    model1_dir  = parent_dir + predicted_video_dir + \"jumping_number_result/resolution_prediction/intervalFrm-1_speedType-ema_minAcc-0.92/video_applied_detection_result/\"\n",
    "    model1_acc_file = model1_dir + \"arr_acc_segment_.pkl\"\n",
    "    arr_acc_model1 = read_whole_data_instances(model1_acc_file)\n",
    "\n",
    "    print(\"arr_acc_model 1 2 mean: \", np.mean(arr_acc_model1), np.mean(arr_acc_model2))\n",
    "    plot_two_scatter(range(0, arr_acc_model1.shape[0]), range(0, arr_acc_model2.shape[0]), arr_acc_model1, arr_acc_model2, \"Segment\", \"Acc\", 'Acc', \"\", model2_dir)\n",
    "    \n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

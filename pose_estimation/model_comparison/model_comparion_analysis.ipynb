{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two models,  cascaded models, unified model\n",
    "\n",
    "\n",
    "import matplotlib \n",
    "matplotlib.use('TKAgg',warn=False, force=True)\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_file_process import read_pickle_data\n",
    "from common_plot import plotOneScatterLine\n",
    "from common_plot import plotOneScatter\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '../../input_output/one_person_diy_video_dataset/' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_scatter(x_lst_1, x_lst_2, y_lst_1, y_lst_2, x_label, y_label_1, y_label_2, title_name, write_dir):\n",
    "    fig,axes=plt.subplots(nrows=2, ncols=1)\n",
    "    axes[0].plot(x_lst_1, y_lst_1, zorder=1) \n",
    "    sc1 = axes[0].scatter(x_lst_1, y_lst_1, marker=\"o\", color=\"r\", zorder=2)\n",
    "    \n",
    "    axes[1].plot(x_lst_2, y_lst_2, zorder=1) \n",
    "    sc2 = axes[1].scatter(x_lst_2,y_lst_2, marker=\"x\", color=\"k\", zorder=2)\n",
    "    \n",
    "    axes[0].set(xlabel=x_label, ylabel=y_label_1)\n",
    "    axes[1].set(xlabel=x_label, ylabel=y_label_2)\n",
    "    \n",
    "    #axes[0].legend([sc1], [\"Admitted\"])\n",
    "    #axes[1].legend([sc2], [\"Not-Admitted\"])\n",
    "    axes[0].set_title(title_name)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    #plt.xticks(size = 12)\n",
    "    #plt.yticks(size = 12)\n",
    "    #plt.yticks(y, yticks)\n",
    "    #plt.show()\n",
    "    if y_label_1 == 'Acc':\n",
    "        plt.savefig(write_dir + 'acc_video.jpg', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(write_dir + 'delay_video.jpg', bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_whole_data_instances(data_file):\n",
    "\n",
    "    data = read_pickle_data(data_file)\n",
    "    print(\"data shape: \", data.shape)\n",
    "\n",
    "    y = np.expand_dims(data, axis=1)    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (1290,)\n",
      "data shape:  (1290,)\n",
      "data shape:  (1515,)\n",
      "data shape:  (1515,)\n",
      "arr_acc_model 1 2 mean:  0.8705679701136528 0.8498516309136567\n",
      "arr_delay_model 1 2 mean:  0.10358578201856289 0.09077608133163255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (662,)\n",
      "data shape:  (662,)\n",
      "data shape:  (735,)\n",
      "data shape:  (735,)\n",
      "arr_acc_model 1 2 mean:  0.8600780619429081 0.8535575025054942\n",
      "arr_delay_model 1 2 mean:  0.045295079367501385 0.04818666567615151\n",
      "data shape:  (1295,)\n",
      "data shape:  (1295,)\n",
      "data shape:  (1150,)\n",
      "data shape:  (1150,)\n",
      "arr_acc_model 1 2 mean:  0.9187599219475976 0.9237484470505213\n",
      "arr_delay_model 1 2 mean:  0.03149248501597971 0.026318231491815475\n",
      "data shape:  (1496,)\n",
      "data shape:  (1496,)\n",
      "data shape:  (1571,)\n",
      "data shape:  (1571,)\n",
      "arr_acc_model 1 2 mean:  0.877203870154709 0.8752715601275783\n",
      "arr_delay_model 1 2 mean:  0.05720485655082251 0.05517700110102294\n",
      "data shape:  (1729,)\n",
      "data shape:  (1729,)\n",
      "data shape:  (1803,)\n",
      "data shape:  (1803,)\n",
      "arr_acc_model 1 2 mean:  0.8431966342603702 0.8378250281354893\n",
      "arr_delay_model 1 2 mean:  0.07834873997805894 0.07036139030412417\n",
      "data shape:  (2503,)\n",
      "data shape:  (2503,)\n",
      "data shape:  (2167,)\n",
      "data shape:  (2167,)\n",
      "arr_acc_model 1 2 mean:  0.9747626109666835 0.9777614859819561\n",
      "arr_delay_model 1 2 mean:  0.046400958895774974 0.07405022628902039\n",
      "data shape:  (2853,)\n",
      "data shape:  (2853,)\n",
      "data shape:  (2654,)\n",
      "data shape:  (2654,)\n",
      "arr_acc_model 1 2 mean:  0.9728991746779297 0.9750002925638654\n",
      "arr_delay_model 1 2 mean:  0.04647052567018932 0.0737394748155808\n",
      "data shape:  (2393,)\n",
      "data shape:  (2393,)\n",
      "data shape:  (2721,)\n",
      "data shape:  (2721,)\n",
      "arr_acc_model 1 2 mean:  0.8271363611277035 0.813390503164431\n",
      "arr_delay_model 1 2 mean:  0.12102195940107657 0.10231883579981593\n",
      "data shape:  (2332,)\n",
      "data shape:  (2332,)\n",
      "data shape:  (2672,)\n",
      "data shape:  (2672,)\n",
      "arr_acc_model 1 2 mean:  0.8430460392555604 0.828966887008831\n",
      "arr_delay_model 1 2 mean:  0.1189386168556537 0.10163522778271675\n",
      "data shape:  (1561,)\n",
      "data shape:  (1561,)\n",
      "data shape:  (1869,)\n",
      "data shape:  (1869,)\n",
      "arr_acc_model 1 2 mean:  0.7886105016066957 0.7491045679832246\n",
      "arr_delay_model 1 2 mean:  0.10417623358655574 0.07548035293874795\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_dir_lst =  ['output_001_dance/', 'output_002_dance/', \\\n",
    "                    'output_003_dance/', 'output_004_dance/',  \\\n",
    "                    'output_005_dance/', 'output_006_yoga/', \\\n",
    "                    'output_007_yoga/', 'output_008_cardio/', \\\n",
    "                    'output_009_cardio/', 'output_010_cardio/']\n",
    "for predicted_video_dir in video_dir_lst:\n",
    "    \n",
    "    model2_dir  = parent_dir + predicted_video_dir + \"jumping_number_result/jumpingNumber_resolution_selection/intervalFrm-1_speedType-ema_minAcc-0.92/video_applied_detection_result/\"\n",
    "    \n",
    "    model2_acc_file = model2_dir + \"arr_acc_segment_.pkl\"\n",
    "    arr_acc_model2 = read_whole_data_instances(model2_acc_file)\n",
    "    model2_delay_file = model2_dir + \"arr_delay_upt_to_segment_.pkl\"\n",
    "    arr_delay_model2 = read_whole_data_instances(model2_delay_file)\n",
    "\n",
    "    model1_dir  = parent_dir + predicted_video_dir + \"jumping_number_result/resolution_prediction/intervalFrm-1_speedType-ema_minAcc-0.92/video_applied_detection_result/\"\n",
    "    model1_acc_file = model1_dir + \"arr_acc_segment_.pkl\"\n",
    "    arr_acc_model1 = read_whole_data_instances(model1_acc_file)\n",
    "    model1_delay_file = model1_dir + \"arr_delay_upt_to_segment_.pkl\"\n",
    "    arr_delay_model1 = read_whole_data_instances(model1_delay_file)\n",
    "    \n",
    "    acc1_mean = np.mean(arr_acc_model1)\n",
    "    acc2_mean = np.mean(arr_acc_model2)\n",
    "    delay1_mean = np.mean(arr_delay_model1)\n",
    "    delay2_mean = np.mean(arr_delay_model2)\n",
    "    print(\"arr_acc_model 1 2 mean: \", acc1_mean, acc2_mean)\n",
    "    print(\"arr_delay_model 1 2 mean: \", delay1_mean, delay2_mean)\n",
    "\n",
    "    plot_two_scatter(range(0, arr_acc_model1.shape[0]), range(0, arr_acc_model2.shape[0]), arr_acc_model1, arr_acc_model2, \"Segment\", \"Acc\", 'Acc', \"\", model2_dir)\n",
    "    \n",
    "    plot_two_scatter(range(0, arr_acc_model1.shape[0]), range(0, arr_acc_model2.shape[0]), arr_acc_model1, arr_acc_model2, \"Segment\", \"Delay (s)\", 'Delay (s)', \"\", model2_dir)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
